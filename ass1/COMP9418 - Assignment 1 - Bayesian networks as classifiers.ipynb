{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Networks as Classifiers\n",
    "\n",
    "## UNSW Sydney, October 2020\n",
    "\n",
    "- Student name 1 - z5272654\n",
    "- Student name 2 - "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "**Submission deadline:** Sunday, 18th October 2020, at 18:00:00.\n",
    "\n",
    "**Late Submission Policy:** The penalty is set at 20% per late day. This is ceiling penalty, so if a group is marked 60/100 and they submitted two days late, they still get 60/100.\n",
    "\n",
    "**Form of Submission:** This is a group assignment. Each group can have up to **two** students. **Only one member of the group should submit the assignment**.\n",
    "\n",
    "You can reuse any piece of source code developed in the tutorials.\n",
    "\n",
    "Submit your files using give. On a CSE Linux machine, type the following on the command-line:\n",
    "\n",
    "``$ give cs9418 ass1 solution.zip``\n",
    "\n",
    "Alternative, you can submit your solution via the [WebCMS](https://webcms3.cse.unsw.edu.au/COMP9418/20T3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries your are allowed to use. No other libraries will be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict as odict\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial task - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\n",
    "    \"BreastDensity\" : [\"Mass\"],\n",
    "    \"Location\" : [\"BC\"],\n",
    "    \"Age\" : [\"BC\"],\n",
    "    \"BC\" : [\"Metastasis\",\"MC\",\"Mass\",\"SkinRetract\",\"NippleDischarge\",\"AD\"],\n",
    "    \"Mass\" : [\"Size\",\"Shape\",\"Margin\"],\n",
    "    \"AD\" : [\"FibrTissueDev\"],\n",
    "    \"Metastasis\" : [\"LymphNodes\"],\n",
    "    \"MC\" : [],\n",
    "    \"Size\" : [],\n",
    "    \"Shape\" : [],\n",
    "    \"FibrTissueDev\" : [\"NippleDischarge\",\"SkinRetract\",\"Spiculation\"],\n",
    "    \"LymphNodes\" : [],\n",
    "    \"SkinRetract\" : [],\n",
    "    \"NippleDischarge\" : [],\n",
    "    \"Spiculation\" : [\"Margin\"],\n",
    "    \"Margin\" : [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``d_separation(G, X, Z, Y)`` that return a boolean: true if **X** is d-separated from **Y** given **Z** in the graph $G$ and false otherwise.\n",
    "\n",
    "* **X**,**Y** and **Z** are python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers, and can be assumed to be nodes of the graph $G$. \n",
    "* $G$ is a graph as defined in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for d_separation(G, X, Z, Y) in one or more cells here\n",
    "#copy the code from tut1\n",
    "def dfs_r(G, v, colour):\n",
    "    colour[v] = 'grey'\n",
    "    for w in G[v]:\n",
    "        if colour[w] == 'white':\n",
    "            dfs_r(G, w, colour)\n",
    "    colour[v] = 'black'\n",
    "\n",
    "def dfs(G, start):\n",
    "    colour = {node: 'white' for node in G.keys()}\n",
    "    dfs_r(G, start, colour)\n",
    "    return colour\n",
    "\n",
    "def d_separation(G,X,Z,Y):\n",
    "# 1. We delete any leaf node W from DAG G as long as W does not belong to X ∪ Y ∪ Z. This process is\n",
    "# repeated until no more nodes can be deleted.\n",
    "    set_union = X.union(Z,Y)\n",
    "    G_prime = copy.deepcopy(G)\n",
    "    k_list = []\n",
    "    for k in G_prime.keys():\n",
    "        k_list.append(k)\n",
    "    for k in k_list:\n",
    "        if not G_prime[k] and k not in set_union:\n",
    "            del G_prime[k]\n",
    "    for k in G_prime.keys():\n",
    "        for item in G_prime[k]:\n",
    "            if item not in G_prime.keys():\n",
    "                G_prime[k].remove(item)\n",
    "#2.We delete all edges outgoing from nodes in Z.\n",
    "\n",
    "    for node in Z:\n",
    "        G_prime[node]=[]\n",
    "\n",
    "#Depth_first search\n",
    "    for i in set(X):\n",
    "        color = dfs(G, i)\n",
    "        for j in set(Y):\n",
    "            if color[j] == 'black':\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case\")\n",
    "        \n",
    "test(d_separation(G, set(['Age']), set(['BC']), set(['AD'])))\n",
    "test(not d_separation(G, set(['Spiculation','LymphNodes']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 2 - Estimate Bayesian Network parameters from data\n",
    "\n",
    "Implement a function ``learn_outcome_space(data)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``data`` and returns a dictionary ``outcomeSpace`` with these values.\n",
    "\n",
    "Implement a function ``learn_bayes_net(G, data, outcomeSpace)`` that learns the parameters of the Bayesian Network $G$. This function should return a dictionary ``prob_tables`` with the all conditional probability tables (one for each node).\n",
    "\n",
    "- ``G`` is a directed acyclic graph. For this part of the assignment, $G$ should be declared according to the breast cancer Bayesian network presented in the diagram in the assignment specification.\n",
    "- ``data`` is a dataframe created from a csv file containing the relevant data. \n",
    "- ``outcomeSpace`` is defined in tutorials.\n",
    "- ``prob_tables`` is a dict from each variable name (node) to a \"factor\". Factors are defined in tutorial 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_outcome_space(data) in one or more cells here\n",
    "def learn_outcome_space(data):\n",
    "    result = {}\n",
    "    for i in set(data.columns):\n",
    "        result[i] = list(set(data[i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "\n",
    "outcomes = outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "test(len(outcomes) == len(answer) and set(outcomes) == set(answer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_bayes_net(G, data, outcomeSpace) in one or more cells here\n",
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "def estProbTable(data, var_name, parent_names, outcomeSpace):\n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            prob_table[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum() \n",
    "    return {'dom': tuple(list(parent_names)+[var_name]), 'table': prob_table}\n",
    "\n",
    "def transposeGraph(G):#exchange the parents and kids node\n",
    "    GT = dict((v, []) for v in G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            GT[w].append(v)\n",
    "\n",
    "    return GT\n",
    "\n",
    "def learn_bayes_net(G, file, outcomeSpace):\n",
    "    prob_tables = odict()\n",
    "    graphT = transposeGraph(G)\n",
    "    for node, parents in graphT.items():\n",
    "        prob_tables[node] = estProbTable(data, node, parents, outcomeSpace)\n",
    "    return prob_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "prob_tables = learn_bayes_net(G, data, outcomeSpace)\n",
    "test(abs(prob_tables['Age']['table'][('35-49',)] - 0.2476) < 0.001)\n",
    "#prob_tables['BC']['dom']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 3 - Bayesian Network Classification\n",
    "\n",
    "Design a new function ``assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)`` that uses the test cases in ``data`` to assess the performance of the Bayesian network defined by ``G`` and ``prob_tables``. Implement the efficient classification procedure discussed in the lectures. Such a function should return the classifier accuracy. \n",
    " * ``class_var`` is the name of the variable you are predicting, using all other variables.\n",
    " * ``outcomeSpace`` was created in task 2\n",
    " \n",
    "Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy.\n",
    "\n",
    "Return just the accuracy:\n",
    "\n",
    "``acc = assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var) in one or more cells here\n",
    "\n",
    "\n",
    "data = data.drop(columns=[\"Metastasis\", \"LymphNodes\"])\n",
    "\n",
    "graph = copy.deepcopy(G)\n",
    "graph.pop(\"Metastasis\")\n",
    "graph.pop(\"LymphNodes\")\n",
    "graph[\"BC\"] = [\"MC\", \"Mass\", \"SkinRetract\", \"NippleDischarge\", \"AD\"]\n",
    "pos = int(len(data) * 0.9)\n",
    "train_data = data[:pos]  # 90%\n",
    "test_data = data[pos:]  # 10%\n",
    "# train_data = data_new[:2000]+data_new[4001:]  # 90%\n",
    "# test_data = data_new[2001:4000]  # 10%\n",
    "prob_tables1 = learn_bayes_net(graph, train_data, outcomeSpace)\n",
    "\n",
    "# initlize the parameters\n",
    "G = graph\n",
    "prob_tables = prob_tables1\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "class_var = 'BC'\n",
    "\n",
    "\n",
    "def assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var):\n",
    "\n",
    "    markov_blanket = set()\n",
    "    for node in G:\n",
    "        if class_var in G[node]:\n",
    "            markov_blanket.add(node)\n",
    "        if node in G[class_var]:\n",
    "            markov_blanket.add(node)\n",
    "            for othernode in G:\n",
    "                if node in G[othernode]:\n",
    "                    markov_blanket.add(othernode)\n",
    "    markov_blanket = list(markov_blanket)\n",
    "    correct_num = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line = data.iloc[i]\n",
    "        outcome_output = []\n",
    "        for outcome in outcomeSpace[class_var]:\n",
    "            p = 1\n",
    "            for node in markov_blanket:\n",
    "                condition = prob_tables[node]['dom']\n",
    "                attr = []\n",
    "                for item in condition:\n",
    "                    if item == class_var:\n",
    "                        attr.append(outcome)\n",
    "                    else:\n",
    "                        attr.append(line[item])\n",
    "\n",
    "                n = len(attr)\n",
    "                if n == 1:\n",
    "                    p = p*prob_tables[node]['table'][attr[0],]\n",
    "                else:\n",
    "                    l = []\n",
    "                    for i in range(n):\n",
    "                        l.append(attr[i])\n",
    "                    o = list(prob_tables[node]['table'].items())\n",
    "                    for i in range(len(o)):\n",
    "                        if list(o[i][0]) == l:\n",
    "                            p = p*o[i][1]\n",
    "            outcome_output.append(p)\n",
    "\n",
    "        if line[class_var] == outcomeSpace[class_var][outcome_output.index(max(outcome_output))]:\n",
    "            correct_num += 1\n",
    "    return correct_num/len(data)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84225"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "\n",
    "acc = assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a function ``cv_bayes_net(G, data, class_var)`` that uses ``learn_outcome_space``, ``learn_bayes_net``and ``assess_bayes_net`` to learn and assess a Bayesian network in a dataset using 10-fold cross-validation. Compute and report the average accuracy over the ten cross-validation runs as well as the standard deviation, e.g.\n",
    "\n",
    "``acc, stddev = cv_bayes_net(G, data, class_var)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_bayes_net(G, data, class_var) in one or more cells here\n",
    "def cv_bayes_net(G, data, class_var):\n",
    "    acc_list = []\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    k = int(len(data)/10) #2000\n",
    "    \n",
    "    for i in range(1,11):\n",
    "        train_data = data[0:(i-1) * k] + data[(i) * k:]\n",
    "        test_data = data[(i-1) * k:i * k]\n",
    "        prob_tables = learn_bayes_net(G, train_data, outcomeSpace)\n",
    "        acc = assess_bayes_net(G, prob_tables, test_data, outcomeSpace, class_var)\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    acc_mean = np.mean(acc_list)\n",
    "    stddev = np.std(acc_list)\n",
    "    return acc_mean,stddev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8422499999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cv_bayes_net(G, data, 'BC')\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 4 - Naïve Bayes Classification\n",
    "\n",
    "Design a new function ``assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var)`` to classify and assess the test cases in a dataset ``data`` according to the Naïve Bayes classifier. To classify each example, use the log probability trick discussed in the lectures. This function should return the accuracy of the classifier in ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var) in one or more cells here\n",
    "def assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var):\n",
    "    \n",
    "    attr = G[class_var]\n",
    "    length = len(data)\n",
    "    \n",
    "    prior_prob = {}\n",
    "    for outcome in outcomeSpace[class_var]:\n",
    "        prior_prob[outcome] = np.sum(data[class_var].values == outcome)/length\n",
    "    \n",
    "    correct_num = 0\n",
    "    for i in range(len(data)):\n",
    "        line = data.iloc[i]\n",
    "        outcome_output = []\n",
    "        for cls in outcomeSpace[class_var]:\n",
    "            p = prior_prob[cls]\n",
    "            for node in attr:\n",
    "                if node != class_var:\n",
    "                    p = p*prob_tables[node]['table'][cls,line[node]]\n",
    "            p = np.log(p)\n",
    "            outcome_output.append(p)\n",
    "\n",
    "        if line[class_var] == outcomeSpace[class_var][outcome_output.index(max(outcome_output))]:\n",
    "            correct_num += 1\n",
    "            \n",
    "    return correct_num/len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc = assess_naive_bayes(naive_graph, prob_tables_with_smooth, test_data, outcomeSpace, 'BC')\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a new function ``cv_naive_bayes(data, class_var)`` that uses ``assess_naive_bayes`` to assess the performance of the Naïve Bayes classifier in a dataset ``data``. To develop this code, perform the following steps:\n",
    "\n",
    "1. Use 10-fold cross-validation to split the data into training and test sets.\n",
    "\n",
    "2. Implement a function ``learn_naive_bayes_structure(outcomeSpace, class_var)`` to create and return a Naïve Bayes graph structure from ``outcomeSpace`` and ``class_var``. \n",
    "\n",
    "3. Use ``learn_bayes_net(G, data, outcomeSpace)`` to learn the Naïve Bayes parameters from a training set ``data``. \n",
    "\n",
    "4. Use ``assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var)`` to compute the accuracy of the Naïve Bayes classifier in a test set ``data``. Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy.\n",
    "\n",
    "Do 10-fold cross-validation, same as above, and return ``acc`` and ``stddev``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_naive_bayes_structure(outcomeSpace, class_var) in one or more cells here\n",
    "def estProbTable_with_smoothing(data, var_name, parent_names, outcomeSpace):\n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            prob_table[tuple(list(parent_combination)+[var_outcome])] = ((var_index & parent_index).sum()+1)/(parent_index.sum() *2)\n",
    "    return {'dom': tuple(list(parent_names)+[var_name]), 'table': prob_table}\n",
    "\n",
    "def learn_bayes_net_with_smoothing(G, file, outcomeSpace):\n",
    "    prob_tables = odict()\n",
    "    graphT = transposeGraph(G)\n",
    "    for node, parents in graphT.items():\n",
    "        prob_tables[node] = estProbTable_with_smoothing(data, node, parents, outcomeSpace)\n",
    "    return prob_tables\n",
    "\n",
    "def learn_naive_bayes_structure(outcomeSpace, class_var):\n",
    "    grpah = defaultdict(list)\n",
    "    graph[class_var] = []\n",
    "    for node in outcomeSpace.keys():\n",
    "        if node == class_var:\n",
    "            continue\n",
    "        else:\n",
    "            grpah[class_var].append(node)\n",
    "            grpah[node] = []\n",
    "    return grpah\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "naive_graph = learn_naive_bayes_structure(outcomeSpace, 'BC')\n",
    "#naive_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('BreastDensity',\n",
       "              {'dom': ('BreastDensity',),\n",
       "               'table': OrderedDict([(('medium',), 0.4991),\n",
       "                            (('low',), 0.19945),\n",
       "                            (('high',), 0.30145)])}),\n",
       "             ('Location',\n",
       "              {'dom': ('Location',),\n",
       "               'table': OrderedDict([(('LowInQuad',), 0.25075),\n",
       "                            (('LolwOutQuad',), 0.2511),\n",
       "                            (('UpInQuad',), 0.25195),\n",
       "                            (('UpOutQuad',), 0.2462)])}),\n",
       "             ('Age',\n",
       "              {'dom': ('Age',),\n",
       "               'table': OrderedDict([(('50-74',), 0.50025),\n",
       "                            (('>75',), 0.1478),\n",
       "                            (('35-49',), 0.248),\n",
       "                            (('<35',), 0.10395)])}),\n",
       "             ('BC',\n",
       "              {'dom': ('Location', 'Age', 'BC'),\n",
       "               'table': OrderedDict([(('LowInQuad', '50-74', 'No'),\n",
       "                             0.5403481012658228),\n",
       "                            (('LowInQuad', '50-74', 'Insitu'),\n",
       "                             0.10482594936708861),\n",
       "                            (('LowInQuad', '50-74', 'Invasive'),\n",
       "                             0.3548259493670886),\n",
       "                            (('LowInQuad', '>75', 'No'), 0.7154471544715447),\n",
       "                            (('LowInQuad', '>75', 'Insitu'),\n",
       "                             0.0989159891598916),\n",
       "                            (('LowInQuad', '>75', 'Invasive'),\n",
       "                             0.1856368563685637),\n",
       "                            (('LowInQuad', '35-49', 'No'), 0.6852750809061489),\n",
       "                            (('LowInQuad', '35-49', 'Insitu'),\n",
       "                             0.17313915857605178),\n",
       "                            (('LowInQuad', '35-49', 'Invasive'),\n",
       "                             0.14158576051779936),\n",
       "                            (('LowInQuad', '<35', 'No'), 0.9668615984405458),\n",
       "                            (('LowInQuad', '<35', 'Insitu'),\n",
       "                             0.017543859649122806),\n",
       "                            (('LowInQuad', '<35', 'Invasive'),\n",
       "                             0.015594541910331383),\n",
       "                            (('LolwOutQuad', '50-74', 'No'),\n",
       "                             0.5492063492063493),\n",
       "                            (('LolwOutQuad', '50-74', 'Insitu'),\n",
       "                             0.1496031746031746),\n",
       "                            (('LolwOutQuad', '50-74', 'Invasive'),\n",
       "                             0.3011904761904762),\n",
       "                            (('LolwOutQuad', '>75', 'No'), 0.6413333333333333),\n",
       "                            (('LolwOutQuad', '>75', 'Insitu'),\n",
       "                             0.15733333333333333),\n",
       "                            (('LolwOutQuad', '>75', 'Invasive'),\n",
       "                             0.20133333333333334),\n",
       "                            (('LolwOutQuad', '35-49', 'No'),\n",
       "                             0.7627257799671593),\n",
       "                            (('LolwOutQuad', '35-49', 'Insitu'),\n",
       "                             0.09688013136288999),\n",
       "                            (('LolwOutQuad', '35-49', 'Invasive'),\n",
       "                             0.14039408866995073),\n",
       "                            (('LolwOutQuad', '<35', 'No'), 0.9868913857677902),\n",
       "                            (('LolwOutQuad', '<35', 'Insitu'),\n",
       "                             0.0056179775280898875),\n",
       "                            (('LolwOutQuad', '<35', 'Invasive'),\n",
       "                             0.00749063670411985),\n",
       "                            (('UpInQuad', '50-74', 'No'), 0.49358460304731355),\n",
       "                            (('UpInQuad', '50-74', 'Insitu'),\n",
       "                             0.161186848436247),\n",
       "                            (('UpInQuad', '50-74', 'Invasive'),\n",
       "                             0.34522854851643947),\n",
       "                            (('UpInQuad', '>75', 'No'), 0.6551724137931034),\n",
       "                            (('UpInQuad', '>75', 'Insitu'),\n",
       "                             0.14323607427055704),\n",
       "                            (('UpInQuad', '>75', 'Invasive'),\n",
       "                             0.20159151193633953),\n",
       "                            (('UpInQuad', '35-49', 'No'), 0.6534810126582279),\n",
       "                            (('UpInQuad', '35-49', 'Insitu'),\n",
       "                             0.18591772151898733),\n",
       "                            (('UpInQuad', '35-49', 'Invasive'),\n",
       "                             0.1606012658227848),\n",
       "                            (('UpInQuad', '<35', 'No'), 0.9468690702087287),\n",
       "                            (('UpInQuad', '<35', 'Insitu'),\n",
       "                             0.020872865275142316),\n",
       "                            (('UpInQuad', '<35', 'Invasive'),\n",
       "                             0.03225806451612903),\n",
       "                            (('UpOutQuad', '50-74', 'No'), 0.4997969955339017),\n",
       "                            (('UpOutQuad', '50-74', 'Insitu'),\n",
       "                             0.19691433211530654),\n",
       "                            (('UpOutQuad', '50-74', 'Invasive'),\n",
       "                             0.3032886723507917),\n",
       "                            (('UpOutQuad', '>75', 'No'), 0.6204481792717087),\n",
       "                            (('UpOutQuad', '>75', 'Insitu'),\n",
       "                             0.12464985994397759),\n",
       "                            (('UpOutQuad', '>75', 'Invasive'),\n",
       "                             0.2549019607843137),\n",
       "                            (('UpOutQuad', '35-49', 'No'), 0.5466988727858293),\n",
       "                            (('UpOutQuad', '35-49', 'Insitu'),\n",
       "                             0.25442834138486314),\n",
       "                            (('UpOutQuad', '35-49', 'Invasive'),\n",
       "                             0.19887278582930756),\n",
       "                            (('UpOutQuad', '<35', 'No'), 0.9465346534653465),\n",
       "                            (('UpOutQuad', '<35', 'Insitu'),\n",
       "                             0.0297029702970297),\n",
       "                            (('UpOutQuad', '<35', 'Invasive'),\n",
       "                             0.023762376237623763)])}),\n",
       "             ('Mass',\n",
       "              {'dom': ('BreastDensity', 'BC', 'Mass'),\n",
       "               'table': OrderedDict([(('medium', 'No', 'Benign'),\n",
       "                             0.10778443113772455),\n",
       "                            (('medium', 'No', 'No'), 0.8922155688622755),\n",
       "                            (('medium', 'No', 'Malign'), 0.0),\n",
       "                            (('medium', 'Insitu', 'Benign'),\n",
       "                             0.3976240391334731),\n",
       "                            (('medium', 'Insitu', 'No'), 0.259958071278826),\n",
       "                            (('medium', 'Insitu', 'Malign'),\n",
       "                             0.3424178895877009),\n",
       "                            (('medium', 'Invasive', 'Benign'),\n",
       "                             0.163575042158516),\n",
       "                            (('medium', 'Invasive', 'No'), 0.2057335581787521),\n",
       "                            (('medium', 'Invasive', 'Malign'),\n",
       "                             0.6306913996627319),\n",
       "                            (('low', 'No', 'Benign'), 0.05795363709032774),\n",
       "                            (('low', 'No', 'No'), 0.9420463629096723),\n",
       "                            (('low', 'No', 'Malign'), 0.0),\n",
       "                            (('low', 'Insitu', 'Benign'), 0.4412296564195298),\n",
       "                            (('low', 'Insitu', 'No'), 0.2423146473779385),\n",
       "                            (('low', 'Insitu', 'Malign'), 0.31645569620253167),\n",
       "                            (('low', 'Invasive', 'Benign'),\n",
       "                             0.1873661670235546),\n",
       "                            (('low', 'Invasive', 'No'), 0.26659528907922914),\n",
       "                            (('low', 'Invasive', 'Malign'),\n",
       "                             0.5460385438972163),\n",
       "                            (('high', 'No', 'Benign'), 0.15007982969664715),\n",
       "                            (('high', 'No', 'No'), 0.8499201703033529),\n",
       "                            (('high', 'No', 'Malign'), 0.0),\n",
       "                            (('high', 'Insitu', 'Benign'),\n",
       "                             0.40749414519906324),\n",
       "                            (('high', 'Insitu', 'No'), 0.20023419203747073),\n",
       "                            (('high', 'Insitu', 'Malign'),\n",
       "                             0.39227166276346603),\n",
       "                            (('high', 'Invasive', 'Benign'),\n",
       "                             0.09668313338038109),\n",
       "                            (('high', 'Invasive', 'No'), 0.10515172900494002),\n",
       "                            (('high', 'Invasive', 'Malign'),\n",
       "                             0.7981651376146789)])}),\n",
       "             ('AD',\n",
       "              {'dom': ('BC', 'AD'),\n",
       "               'table': OrderedDict([(('No', 'No'), 0.9480665648364016),\n",
       "                            (('No', 'Yes'), 0.05193343516359836),\n",
       "                            (('Insitu', 'No'), 0.7036645525017619),\n",
       "                            (('Insitu', 'Yes'), 0.2963354474982382),\n",
       "                            (('Invasive', 'No'), 0.5471098877831887),\n",
       "                            (('Invasive', 'Yes'), 0.45289011221681136)])}),\n",
       "             ('MC',\n",
       "              {'dom': ('BC', 'MC'),\n",
       "               'table': OrderedDict([(('No', 'No'), 0.9720234745558325),\n",
       "                            (('No', 'Yes'), 0.027976525444167538),\n",
       "                            (('Insitu', 'No'), 0.48731501057082455),\n",
       "                            (('Insitu', 'Yes'), 0.5126849894291755),\n",
       "                            (('Invasive', 'No'), 0.5308066906627144),\n",
       "                            (('Invasive', 'Yes'), 0.46919330933728565)])}),\n",
       "             ('Size',\n",
       "              {'dom': ('Mass', 'Size'),\n",
       "               'table': OrderedDict([(('Benign', '<1cm'), 0.10352286773794808),\n",
       "                            (('Benign', '>3cm'), 0.6396786155747837),\n",
       "                            (('Benign', '1-3cm'), 0.2567985166872682),\n",
       "                            (('No', '<1cm'), 1.0),\n",
       "                            (('No', '>3cm'), 0.0),\n",
       "                            (('No', '1-3cm'), 0.0),\n",
       "                            (('Malign', '<1cm'), 0.2871646120377085),\n",
       "                            (('Malign', '>3cm'), 0.15228426395939088),\n",
       "                            (('Malign', '1-3cm'), 0.5605511240029006)])}),\n",
       "             ('Shape',\n",
       "              {'dom': ('Mass', 'Shape'),\n",
       "               'table': OrderedDict([(('Benign', 'Round'), 0.6529666254635352),\n",
       "                            (('Benign', 'Other'), 0.055315203955500616),\n",
       "                            (('Benign', 'Irregular'), 0.05253399258343634),\n",
       "                            (('Benign', 'Oval'), 0.2391841779975278),\n",
       "                            (('No', 'Round'), 0.0),\n",
       "                            (('No', 'Other'), 1.0),\n",
       "                            (('No', 'Irregular'), 0.0),\n",
       "                            (('No', 'Oval'), 0.0),\n",
       "                            (('Malign', 'Round'), 0.10490693739424704),\n",
       "                            (('Malign', 'Other'), 0.0),\n",
       "                            (('Malign', 'Irregular'), 0.7416001933768431),\n",
       "                            (('Malign', 'Oval'), 0.15349286922890984)])}),\n",
       "             ('FibrTissueDev',\n",
       "              {'dom': ('AD', 'FibrTissueDev'),\n",
       "               'table': OrderedDict([(('No', 'No'), 0.6504213997801392),\n",
       "                            (('No', 'Yes'), 0.34957860021986076),\n",
       "                            (('Yes', 'No'), 0.25592939878654164),\n",
       "                            (('Yes', 'Yes'), 0.7440706012134584)])}),\n",
       "             ('SkinRetract',\n",
       "              {'dom': ('BC', 'FibrTissueDev', 'SkinRetract'),\n",
       "               'table': OrderedDict([(('No', 'No', 'No'), 0.9513218098627352),\n",
       "                            (('No', 'No', 'Yes'), 0.04867819013726487),\n",
       "                            (('No', 'Yes', 'No'), 0.6536862830890396),\n",
       "                            (('No', 'Yes', 'Yes'), 0.3463137169109604),\n",
       "                            (('Insitu', 'No', 'No'), 0.7562417871222076),\n",
       "                            (('Insitu', 'No', 'Yes'), 0.24375821287779237),\n",
       "                            (('Insitu', 'Yes', 'No'), 0.32750759878419455),\n",
       "                            (('Insitu', 'Yes', 'Yes'), 0.6724924012158054),\n",
       "                            (('Invasive', 'No', 'No'), 0.6439670932358318),\n",
       "                            (('Invasive', 'No', 'Yes'), 0.3560329067641682),\n",
       "                            (('Invasive', 'Yes', 'No'), 0.15660749506903354),\n",
       "                            (('Invasive', 'Yes', 'Yes'),\n",
       "                             0.8433925049309665)])}),\n",
       "             ('NippleDischarge',\n",
       "              {'dom': ('BC', 'FibrTissueDev', 'NippleDischarge'),\n",
       "               'table': OrderedDict([(('No', 'No', 'No'), 0.9508134214539908),\n",
       "                            (('No', 'No', 'Yes'), 0.04918657854600915),\n",
       "                            (('No', 'Yes', 'No'), 0.6644060380660687),\n",
       "                            (('No', 'Yes', 'Yes'), 0.3355939619339313),\n",
       "                            (('Insitu', 'No', 'No'), 0.7687253613666228),\n",
       "                            (('Insitu', 'No', 'Yes'), 0.23127463863337713),\n",
       "                            (('Insitu', 'Yes', 'No'), 0.3662613981762918),\n",
       "                            (('Insitu', 'Yes', 'Yes'), 0.6337386018237082),\n",
       "                            (('Invasive', 'No', 'No'), 0.6640767824497258),\n",
       "                            (('Invasive', 'No', 'Yes'), 0.3359232175502742),\n",
       "                            (('Invasive', 'Yes', 'No'), 0.15345167652859962),\n",
       "                            (('Invasive', 'Yes', 'Yes'),\n",
       "                             0.8465483234714004)])}),\n",
       "             ('Spiculation',\n",
       "              {'dom': ('FibrTissueDev', 'Spiculation'),\n",
       "               'table': OrderedDict([(('No', 'No'), 0.8502332008982553),\n",
       "                            (('No', 'Yes'), 0.1497667991017447),\n",
       "                            (('Yes', 'No'), 0.2550463072904298),\n",
       "                            (('Yes', 'Yes'), 0.7449536927095701)])}),\n",
       "             ('Margin',\n",
       "              {'dom': ('Mass', 'Spiculation', 'Margin'),\n",
       "               'table': OrderedDict([(('Benign', 'No', 'Well-defined'),\n",
       "                             0.7476290832455216),\n",
       "                            (('Benign', 'No', 'Ill-defined'),\n",
       "                             0.2523709167544784),\n",
       "                            (('Benign', 'Yes', 'Well-defined'),\n",
       "                             0.3572496263079223),\n",
       "                            (('Benign', 'Yes', 'Ill-defined'),\n",
       "                             0.6427503736920778),\n",
       "                            (('No', 'No', 'Well-defined'), 1.0),\n",
       "                            (('No', 'No', 'Ill-defined'), 0.0),\n",
       "                            (('No', 'Yes', 'Well-defined'), 0.0),\n",
       "                            (('No', 'Yes', 'Ill-defined'), 1.0),\n",
       "                            (('Malign', 'No', 'Well-defined'),\n",
       "                             0.2064975522919448),\n",
       "                            (('Malign', 'No', 'Ill-defined'),\n",
       "                             0.7935024477080552),\n",
       "                            (('Malign', 'Yes', 'Well-defined'),\n",
       "                             0.05555555555555555),\n",
       "                            (('Malign', 'Yes', 'Ill-defined'),\n",
       "                             0.9444444444444444)])})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_tables_with_smooth = learn_bayes_net_with_smoothing(naive_graph, train_data, outcomeSpace)\n",
    "prob_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_naive_bayes(data, class_var) in one or more cells here\n",
    "def cv_naive_bayes(data, class_var):\n",
    "    acc_list = []\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    graph = learn_naive_bayes_structure(outcomeSpace,class_var)\n",
    "    k = int(len(data) / 10)  # 2000\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        train_data = data[0:(i - 1) * k] + data[(i) * k:]\n",
    "        test_data = data[(i - 1) * k:i * k]\n",
    "        prob_tables = learn_bayes_net(graph, train_data, outcomeSpace)\n",
    "        acc = assess_bayes_net(graph, prob_tables, test_data, outcomeSpace, class_var)\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    acc_mean = np.mean(acc_list)\n",
    "    stddev = np.std(acc_list)\n",
    "    return acc_mean, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cv_naive_bayes(data, 'BC')\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 5 - Tree-augmented Naïve Bayes Classification\n",
    "\n",
    "Similarly to the previous task, implement a Tree-augmented Naïve Bayes (TAN) classifier and evaluate your implementation in the breast cancer dataset. Design a function ``learn_tan_structure(data, outcomeSpace, class_var)`` to learn the TAN structure (graph) from the ``data`` and returns such a structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_tan_structure(data, outcomeSpace, class_var) in one or more cells here\n",
    "def mi_information(data, ai, aj, cls):\n",
    "    val_ai = set(data[ai])\n",
    "    val_aj = set(data[aj])\n",
    "    val_cls = set(data[cls])\n",
    "    length = len(data)\n",
    "    mi_prob = []\n",
    "    m = 0\n",
    "\n",
    "    for c in val_cls:\n",
    "        for i in val_ai:\n",
    "            for j in val_aj:\n",
    "                \n",
    "                arr = data[[ai, aj, cls]].values == [i, j, c]\n",
    "                acc = 0\n",
    "                for a in arr:\n",
    "                    if all(a):\n",
    "                        acc += 1\n",
    "                all_paiajc = (acc+1)/(length * 2)\n",
    "                condition_length = np.sum(data[cls].values == [c])\n",
    "                \n",
    "                paiajc = (acc+1)/(condition_length+length)\n",
    "                \n",
    "                arr1 = data[[ai, cls]].values == [i, c]\n",
    "                acc1 = 0\n",
    "                for a in arr1:\n",
    "                    if all(a):\n",
    "                        acc1 += 1\n",
    "                paic = (acc1+1)/(condition_length+length)\n",
    "                \n",
    "                arr2 = data[[aj, cls]].values == [j, c]\n",
    "                acc2 = 0\n",
    "                for a in arr2:\n",
    "                    if all(a):\n",
    "                        acc2 += 1\n",
    "                pajc = (acc2 + 1) / (condition_length + length)\n",
    "                m += all_paiajc * math.log(paiajc / (paic * pajc))\n",
    "    return -m\n",
    "\n",
    "def prim(G, s):\n",
    "    S = {s}\n",
    "    Q = []\n",
    "    tree = []\n",
    "    for e in G[s]:\n",
    "        pq.heappush(Q, [e[1], s, e[0]])\n",
    "    while len(Q) > 0:\n",
    "        [cost, v, u] = pq.heappop(Q)\n",
    "        if not u in S:\n",
    "            S.add(u)\n",
    "            tree.append([v, u, cost])\n",
    "            for e in G[u]:\n",
    "                if not e[0] in S:\n",
    "                    pq.heappush(Q, [e[1], u, e[0]])\n",
    "    return tree\n",
    "def learn_tan_structure(data, outcomeSpace, class_var):\n",
    "    \n",
    "    attr = list(data.columns)\n",
    "    attr.remove(class_var)\n",
    "    length = len(attr)\n",
    "    maps = {}\n",
    "    for a in attr:\n",
    "        maps[a] = []\n",
    "    for a in attr:\n",
    "        for b in attr:\n",
    "            if b != a:\n",
    "                maps[a].append([b, mi_information(data, a, b, class_var)])\n",
    "    tree = prim(maps, attr[0])\n",
    "\n",
    "    tangraph = defaultdict(list)\n",
    "\n",
    "    for i in attr:\n",
    "        if i != class_var:\n",
    "            tangraph[class_var].append(i)\n",
    "    for edge in tree:\n",
    "        if edge[0] != class_var:\n",
    "            tangraph[edge[0]].append(edge[1])\n",
    "        if edge[1] not in tangraph:\n",
    "            tangraph[edge[1]] = []\n",
    "    return tangraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "tan_graph = learn_tan_structure(train_data, outcomeSpace, class_var)\n",
    "test(len(tan_graph['BC']) == len(tan_graph)-1)\n",
    "test('FibrTissueDev' in tan_graph['Spiculation'] or 'Spiculation' in tan_graph['FibrTissueDev'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the other tasks, design a function ``cv_tan(data, class_var)`` that uses 10-fold cross-validation to assess the performance of the TAN classifier from ``data``. Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy. This function should use the ``learn_tan_structure`` as well as other functions defined in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for cv_tan(data, class_var) in one or more cells here\n",
    "def cv_tan(data, class_var):\n",
    "    acc_list = []\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    k = int(len(data) / 10)  # 2000\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        train_data = data[0:(i - 1) * k] + data[i * k:]\n",
    "        \n",
    "        test_data = data[(i - 1) * k:i * k]\n",
    "        \n",
    "        tan_graph = learn_tan_structure(train_data, outcomeSpace, class_var)\n",
    "        \n",
    "        prob_tables = learn_bayes_net(tan_graph, train_data, outcomeSpace)\n",
    "        \n",
    "        acc = assess_bayes_net(tan_graph, prob_tables, test_data, outcomeSpace, class_var)\n",
    "        \n",
    "        acc_list.append(acc)\n",
    "\n",
    "    acc_mean = np.mean(acc_list)\n",
    "    stddev = np.std(acc_list)\n",
    "    return acc_mean, stddev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time taken: 39.59582853317261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7906500000000001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "starttime = time.time()\n",
    "acc, stddev = cv_tan(data, 'BC')\n",
    "endtime = time.time()\n",
    "print('total time taken:',endtime-starttime)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 6 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results (accuracy). Use plots to illustrate your results.\n",
    "\n",
    "b. Discuss the complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter notebook. Develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please, be concise and objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"596pt\" height=\"580pt\"\r\n",
       " viewBox=\"0.00 0.00 595.95 580.12\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(292.733 287.1)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-292.733,293.02 -292.733,-287.1 303.22,-287.1 303.22,293.02 -292.733,293.02\"/>\r\n",
       "<!-- BC -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>BC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"0.501103\" cy=\"-2.79108\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"0.501103\" y=\"0.908916\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BC</text>\r\n",
       "</g>\r\n",
       "<!-- SkinRetract -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>SkinRetract</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-220.251\" cy=\"-142.591\" rx=\"53.0913\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-220.251\" y=\"-138.891\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SkinRetract</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;SkinRetract -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>BC&#45;&gt;SkinRetract</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-19.0892,-15.1974C-56.7591,-39.0532 -139.695,-91.5754 -186.46,-121.191\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-188.453,-118.311 -195.029,-126.618 -184.708,-124.224 -188.453,-118.311\"/>\r\n",
       "</g>\r\n",
       "<!-- Size -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>Size</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"174.893\" cy=\"193.622\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"174.893\" y=\"197.322\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Size</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Size -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>BC&#45;&gt;Size</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M14.4776,12.9502C45.166,47.5138 118.557,130.173 154.44,170.586\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"157.07,168.277 161.092,178.079 151.836,172.925 157.07,168.277\"/>\r\n",
       "</g>\r\n",
       "<!-- Location -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>Location</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-6.44965\" cy=\"-265.1\" rx=\"42.7926\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-6.44965\" y=\"-261.4\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Location</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Location -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>BC&#45;&gt;Location</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M0.0233502,-20.8206C-1.1646,-65.6517 -4.25946,-182.446 -5.69635,-236.672\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-9.20234,-236.855 -5.96855,-246.944 -2.20479,-237.04 -9.20234,-236.855\"/>\r\n",
       "</g>\r\n",
       "<!-- Shape -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>Shape</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"215.348\" cy=\"-155.505\" rx=\"33.2948\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"215.348\" y=\"-151.805\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Shape</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Shape -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>BC&#45;&gt;Shape</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M19.1915,-16.0763C56.8059,-42.8127 141.861,-103.27 186.602,-135.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.808,-138.091 194.987,-141.032 188.864,-132.386 184.808,-138.091\"/>\r\n",
       "</g>\r\n",
       "<!-- BreastDensity -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>BreastDensity</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-128.191\" cy=\"-228.631\" rx=\"61.1893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-128.191\" y=\"-224.931\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BreastDensity</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;BreastDensity -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>BC&#45;&gt;BreastDensity</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-9.17173,-19.7658C-31.4211,-58.8109 -86.3665,-155.234 -113.099,-202.146\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-116.141,-200.415 -118.051,-210.837 -110.059,-203.881 -116.141,-200.415\"/>\r\n",
       "</g>\r\n",
       "<!-- Margin -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>Margin</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"257.897\" cy=\"-36.1662\" rx=\"36.2938\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"257.897\" y=\"-32.4662\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Margin</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Margin -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>BC&#45;&gt;Margin</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27.0775,-6.2371C70.8802,-11.9168 158.732,-23.308 212.522,-30.2826\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.109,-33.7584 222.476,-31.5734 213.01,-26.8165 212.109,-33.7584\"/>\r\n",
       "</g>\r\n",
       "<!-- FibrTissueDev -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>FibrTissueDev</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"59.8496\" cy=\"271.02\" rx=\"64.189\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"59.8496\" y=\"274.72\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FibrTissueDev</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;FibrTissueDev -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>BC&#45;&gt;FibrTissueDev</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4.39512,15.1744C14.4976,61.7835 41.6057,186.85 53.7816,243.025\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.2434,242.474 55.9412,252.989 50.4022,243.957 57.2434,242.474\"/>\r\n",
       "</g>\r\n",
       "<!-- MC -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>MC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-240.69\" cy=\"102.39\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-240.69\" y=\"106.09\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MC</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;MC -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>BC&#45;&gt;MC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-22.1896,7.10407C-65.2855,25.8978 -159.086,66.8033 -208.6,88.3956\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-207.319,91.6551 -217.884,92.4443 -210.117,85.2387 -207.319,91.6551\"/>\r\n",
       "</g>\r\n",
       "<!-- Mass -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>Mass</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-47.7677\" cy=\"204.188\" rx=\"30.5947\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-47.7677\" y=\"207.888\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Mass</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Mass -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>BC&#45;&gt;Mass</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-3.69799,15.2149C-12.1314,51.3777 -31.1795,133.057 -41.2476,176.23\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-37.8642,177.133 -43.5439,186.076 -44.6812,175.543 -37.8642,177.133\"/>\r\n",
       "</g>\r\n",
       "<!-- Spiculation -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>Spiculation</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"247.875\" cy=\"89.5191\" rx=\"51.1914\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"247.875\" y=\"93.2191\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Spiculation</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Spiculation -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>BC&#45;&gt;Spiculation</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M24.2203,6.06001C65.3178,21.396 150.396,53.1437 202.962,72.7593\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.235,69.4988 212.381,76.2741 201.788,76.0571 204.235,69.4988\"/>\r\n",
       "</g>\r\n",
       "<!-- AD -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>AD</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-166.584\" cy=\"225.699\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-166.584\" y=\"229.399\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AD</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;AD -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>BC&#45;&gt;AD</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-11.5152,13.6414C-40.477,53.247 -114.27,154.159 -148.561,201.053\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-145.948,203.41 -154.676,209.416 -151.599,199.278 -145.948,203.41\"/>\r\n",
       "</g>\r\n",
       "<!-- Age -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>Age</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-261.733\" cy=\"-23.1352\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-261.733\" y=\"-19.4352\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Age -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>BC&#45;&gt;Age</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-26.5748,-4.89164C-73.8071,-8.55592 -171.311,-16.1203 -224.735,-20.2649\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-225.105,-16.783 -234.804,-21.0461 -224.563,-23.762 -225.105,-16.783\"/>\r\n",
       "</g>\r\n",
       "<!-- NippleDischarge -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>NippleDischarge</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"115.302\" cy=\"-232.52\" rx=\"70.6878\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"115.302\" y=\"-228.82\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">NippleDischarge</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;NippleDischarge -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>BC&#45;&gt;NippleDischarge</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M9.12986,-20.0581C28.9363,-59.6927 77.7882,-157.45 101.69,-205.279\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.6557,-207.038 106.257,-214.418 104.917,-203.908 98.6557,-207.038\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x112b6469970>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Develop your report in one or more cells here\n",
    "def plot_graph(graph):\n",
    "    dot = Digraph(engine=\"neato\", comment='Direct graph example')\n",
    "    dot.attr(overlap=\"false\", splines=\"true\")\n",
    "    \n",
    "    for v in graph.keys():\n",
    "        dot.node(v)              \n",
    "    \n",
    "    for v in graph.keys():\n",
    "        for w in graph[v]:\n",
    "            dot.edge(v,w)\n",
    "    return dot\n",
    "\n",
    "\n",
    "dot4 = plot_graph(naive_graph)\n",
    "dot4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"578pt\" height=\"543pt\"\r\n",
       " viewBox=\"0.00 0.00 577.81 542.98\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(312.119 256.532)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-312.119,286.445 -312.119,-256.532 265.692,-256.532 265.692,286.445 -312.119,286.445\"/>\r\n",
       "<!-- BC -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>BC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-0.132899\" cy=\"7.51992\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-0.132899\" y=\"11.2199\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BC</text>\r\n",
       "</g>\r\n",
       "<!-- BreastDensity -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>BreastDensity</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-156.658\" cy=\"-190.528\" rx=\"61.1893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-156.658\" y=\"-186.828\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BreastDensity</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;BreastDensity -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>BC&#45;&gt;BreastDensity</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-12.942,-8.68717C-40.1283,-43.0854 -103.781,-123.624 -136.482,-165\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-139.323,-162.95 -142.778,-172.966 -133.832,-167.291 -139.323,-162.95\"/>\r\n",
       "</g>\r\n",
       "<!-- Mass -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>Mass</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27.3808\" cy=\"-178.553\" rx=\"30.5947\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27.3808\" y=\"-174.853\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Mass</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Mass -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>BC&#45;&gt;Mass</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2.55532,-10.6603C7.37563,-43.2596 17.5184,-111.854 23.2352,-150.516\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"19.797,-151.192 24.7221,-160.573 26.7217,-150.168 19.797,-151.192\"/>\r\n",
       "</g>\r\n",
       "<!-- Shape -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>Shape</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-150.966\" cy=\"-76.7793\" rx=\"33.2948\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-150.966\" y=\"-73.0793\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Shape</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Shape -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>BC&#45;&gt;Shape</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-21.1056,-4.20152C-46.3781,-18.3261 -89.1162,-42.212 -118.622,-58.7025\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-120.676,-55.841 -127.698,-63.775 -117.261,-61.9515 -120.676,-55.841\"/>\r\n",
       "</g>\r\n",
       "<!-- Size -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>Size</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"203.551\" cy=\"-100.405\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"203.551\" y=\"-96.7053\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Size</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Size -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>BC&#45;&gt;Size</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M21.2798,-3.82599C57.6484,-23.0965 131.587,-62.2743 173.25,-84.3502\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.644,-87.4601 182.119,-89.0495 174.922,-81.2748 171.644,-87.4601\"/>\r\n",
       "</g>\r\n",
       "<!-- Margin -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>Margin</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171.07\" cy=\"-169.871\" rx=\"36.2938\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"171.07\" y=\"-166.171\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Margin</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Margin -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>BC&#45;&gt;Margin</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M14.7608,-7.91207C44.7612,-38.9969 112.634,-109.323 148.26,-146.237\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.885,-148.816 155.348,-153.58 150.922,-143.954 145.885,-148.816\"/>\r\n",
       "</g>\r\n",
       "<!-- Spiculation -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>Spiculation</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"210.346\" cy=\"23.1229\" rx=\"51.1914\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"210.346\" y=\"26.8229\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Spiculation</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Spiculation -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>BC&#45;&gt;Spiculation</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M26.9527,9.5278C57.864,11.8193 109.384,15.6385 149.96,18.6464\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"150.307,15.1625 160.021,19.3923 149.79,22.1433 150.307,15.1625\"/>\r\n",
       "</g>\r\n",
       "<!-- FibrTissueDev -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>FibrTissueDev</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"92.9113\" cy=\"175.578\" rx=\"64.189\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"92.9113\" y=\"179.278\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FibrTissueDev</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;FibrTissueDev -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>BC&#45;&gt;FibrTissueDev</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M9.30071,24.5591C25.4748,53.773 58.6209,113.642 77.9675,148.587\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"81.2511,147.291 83.0327,157.735 75.127,150.682 81.2511,147.291\"/>\r\n",
       "</g>\r\n",
       "<!-- NippleDischarge -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>NippleDischarge</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-90.1908\" cy=\"210.012\" rx=\"70.6878\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-90.1908\" y=\"213.712\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">NippleDischarge</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;NippleDischarge -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>BC&#45;&gt;NippleDischarge</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-7.81118,24.7843C-23.4777,60.0099 -59.2339,140.406 -78.0694,182.757\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-74.8838,184.208 -82.1455,191.922 -81.2797,181.363 -74.8838,184.208\"/>\r\n",
       "</g>\r\n",
       "<!-- SkinRetract -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>SkinRetract</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1.8953\" cy=\"264.445\" rx=\"53.0913\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1.8953\" y=\"268.145\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SkinRetract</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;SkinRetract -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>BC&#45;&gt;SkinRetract</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M0.00971979,25.5864C0.358113,69.7196 1.25451,183.272 1.6734,236.335\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5.17369,236.371 1.75284,246.399 -1.82609,236.427 5.17369,236.371\"/>\r\n",
       "</g>\r\n",
       "<!-- AD -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>AD</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"217.753\" cy=\"150.791\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"217.753\" y=\"154.491\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AD</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;AD -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>BC&#45;&gt;AD</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M19.203,20.2342C57.9664,45.723 145.292,103.144 190.094,132.603\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.028,129.686 198.46,138.105 188.182,135.535 192.028,129.686\"/>\r\n",
       "</g>\r\n",
       "<!-- Age -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>Age</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-197.908\" cy=\"109.9\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-197.908\" y=\"113.6\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Age</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Age -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>BC&#45;&gt;Age</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-21.6748,18.6712C-56.8949,36.9032 -126.917,73.1506 -167.288,94.0489\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-165.903,97.273 -176.392,98.762 -169.121,91.0566 -165.903,97.273\"/>\r\n",
       "</g>\r\n",
       "<!-- Location -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>Location</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-265.223\" cy=\"9.30088\" rx=\"42.7926\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-265.223\" y=\"13.0009\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Location</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;Location -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>BC&#45;&gt;Location</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-27.5037,7.70381C-70.9661,7.9958 -156.537,8.57069 -212.277,8.94517\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-212.297,12.4453 -222.321,9.01265 -212.344,5.44545 -212.297,12.4453\"/>\r\n",
       "</g>\r\n",
       "<!-- MC -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>MC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"-63.8296\" cy=\"-234.532\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"-63.8296\" y=\"-230.832\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MC</text>\r\n",
       "</g>\r\n",
       "<!-- BC&#45;&gt;MC -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>BC&#45;&gt;MC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-4.81667,-10.2788C-15.8139,-52.0691 -43.351,-156.712 -56.551,-206.873\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-59.9788,-206.146 -59.139,-216.708 -53.2092,-207.928 -59.9788,-206.146\"/>\r\n",
       "</g>\r\n",
       "<!-- BreastDensity&#45;&gt;Mass -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>BreastDensity&#45;&gt;Mass</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-96.9059,-186.64C-69.5383,-184.859 -37.8106,-182.795 -13.2621,-181.197\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-12.9661,-184.686 -3.21446,-180.544 -13.4206,-177.7 -12.9661,-184.686\"/>\r\n",
       "</g>\r\n",
       "<!-- Mass&#45;&gt;Shape -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>Mass&#45;&gt;Shape</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5.15365,-165.869C-26.0474,-148.064 -83.0166,-115.554 -118.832,-95.1166\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-117.473,-91.8623 -127.893,-89.9459 -120.942,-97.9421 -117.473,-91.8623\"/>\r\n",
       "</g>\r\n",
       "<!-- Mass&#45;&gt;Size -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>Mass&#45;&gt;Size</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.8764,-167.687C83.1603,-153.809 137.358,-129.768 171.786,-114.496\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.215,-117.691 180.936,-110.437 170.376,-111.292 173.215,-117.691\"/>\r\n",
       "</g>\r\n",
       "<!-- Mass&#45;&gt;Margin -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>Mass&#45;&gt;Margin</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.8536,-176.712C77.2686,-175.539 102.798,-173.996 124.7,-172.673\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.023,-176.16 134.794,-172.063 124.601,-169.173 125.023,-176.16\"/>\r\n",
       "</g>\r\n",
       "<!-- Shape&#45;&gt;Age -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>Shape&#45;&gt;Age</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-155.467,-58.8797C-163.668,-26.2642 -181.1,43.0575 -190.879,81.9479\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-187.587,83.2097 -193.42,92.0542 -194.376,81.5025 -187.587,83.2097\"/>\r\n",
       "</g>\r\n",
       "<!-- Shape&#45;&gt;MC -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>Shape&#45;&gt;MC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-141.308,-94.2643C-125.983,-122.009 -96.0079,-176.276 -78.1685,-208.573\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-81.1648,-210.387 -73.266,-217.448 -75.0374,-207.003 -81.1648,-210.387\"/>\r\n",
       "</g>\r\n",
       "<!-- Margin&#45;&gt;Spiculation -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>Margin&#45;&gt;Spiculation</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170.977,-151.734C171.171,-137.626 172.027,-117.608 174.951,-100.317 180.635,-66.6997 192.159,-29.1958 200.518,-4.44564\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"203.829,-5.58008 203.769,5.01459 197.209,-3.30508 203.829,-5.58008\"/>\r\n",
       "</g>\r\n",
       "<!-- Spiculation&#45;&gt;FibrTissueDev -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>Spiculation&#45;&gt;FibrTissueDev</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.875,40.6115C176.279,67.3494 136.838,118.552 112.899,149.629\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.462,152.038 106.587,157.824 109.917,147.766 115.462,152.038\"/>\r\n",
       "</g>\r\n",
       "<!-- FibrTissueDev&#45;&gt;NippleDischarge -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>FibrTissueDev&#45;&gt;NippleDischarge</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M39.4584,185.63C19.8644,189.315 -2.56335,193.533 -23.1946,197.413\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-22.6835,200.878 -33.1581,199.286 -23.9772,193.999 -22.6835,200.878\"/>\r\n",
       "</g>\r\n",
       "<!-- FibrTissueDev&#45;&gt;SkinRetract -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>FibrTissueDev&#45;&gt;SkinRetract</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.9294,193.136C61.2534,206.489 42.2647,225.029 27.0773,239.858\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"29.1303,242.745 19.5301,247.227 24.24,237.736 29.1303,242.745\"/>\r\n",
       "</g>\r\n",
       "<!-- FibrTissueDev&#45;&gt;AD -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>FibrTissueDev&#45;&gt;AD</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.494,165.138C157.738,162.707 170.501,160.173 181.833,157.923\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.291,154.462 191.782,155.947 182.655,161.328 181.291,154.462\"/>\r\n",
       "</g>\r\n",
       "<!-- Age&#45;&gt;Location -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>Age&#45;&gt;Location</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-209.023,93.2877C-219.549,77.5573 -235.519,53.6916 -247.748,35.4159\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"-250.758,37.2108 -253.411,26.9534 -244.94,33.3179 -250.758,37.2108\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x112b6469c10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"bayes_net.jpg\",width=300,height=300>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"bayes_net.jpg\",width=300,height=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"naive_bayes.jpg\",width=300,height=300>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"naive_bayes.jpg\",width=300,height=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"tan.jpg\",width=300,height=300>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"tan.jpg\",width=300,height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  After implementing three classifiers,from my model, I find that Bayes Network has the top-1 accuracy among the three, following by the Naïve Bayes classfier Classification, and tree-augmented Naïve Bayes Classification has the lowest accuracy. The average accuracys of them are 84.2%,79.2% and 79.0% respectively. This is partly not correct.Theoretically, TAN should have the highest accuracy among three.  Maybe there is something wrong with my TAN implement.\n",
    "  From the coding difficulty, NBC is the easiest one among three, but it has rather poor performance in classification. From the naive bayes graph, we can easily know that every node except the \"class variable\" is independent(can also learn from the Naïve Bayes assumption).The Bayes Network classfier is a lot more difficult to implement compared to the NBC. In BNC, all the node are discrete, and some of them has strong dependency. Because of this, to assess this classifier from the probability table, I find the markov blanket of node \"BC\" which make the classification more accurate. Due to this property of BNC, it can learn much causal relationship between the variables, making it strong to avoid overfitting.\n",
    "  As an expansion of NBC, TAN can learn\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
